{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P-q9lySG9-H"
      },
      "source": [
        "# 1. Loading & Understanding the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJCFvmICGolp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niWGwAz4Hmvo"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k-vWnWKH0aF"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBs-IDUxH2t6"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRLB3rVoIWME"
      },
      "source": [
        "# 2. Cleaning the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTva9uG2IbMD"
      },
      "outputs": [],
      "source": [
        "data = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh6CgqypIElF"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vntuyEZmJGml"
      },
      "outputs": [],
      "source": [
        "missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
        "missing_percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWbuga-2I3I9"
      },
      "outputs": [],
      "source": [
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZBgr1UEI9_T"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJprhsk8JCpj"
      },
      "outputs": [],
      "source": [
        "data.pickup_datetime = pd.to_datetime(data.pickup_datetime)\n",
        "data.dropoff_datetime = pd.to_datetime(data.dropoff_datetime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Brt0DFGpOZv9"
      },
      "outputs": [],
      "source": [
        "data[['pickup_datetime', 'dropoff_datetime']].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gym1f9zgOdhF"
      },
      "outputs": [],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EyAxryBOzmE"
      },
      "outputs": [],
      "source": [
        "data[data['trip_duration'] <= 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuF8trC_PcV9"
      },
      "outputs": [],
      "source": [
        "data['passenger_count'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBMOq-IlQTkT"
      },
      "outputs": [],
      "source": [
        "data['trip_duration_minutes'] = (data['trip_duration'] / 60).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HRlfUc5P8pL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x=data['trip_duration_minutes'])\n",
        "plt.xlabel('Trip Duration (minutes)')\n",
        "plt.title('Boxplot of Trip Duration')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hasqpw3DWtkD"
      },
      "outputs": [],
      "source": [
        "data['trip_duration_minutes'].quantile([0.95, 0.99, 0.999])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCWNFUOdXoQq"
      },
      "source": [
        "95% of trips are under 35 minutes → Most trips are short.  \n",
        "99% of trips are under 55 minutes → Almost all normal trips fit here.  \n",
        "99.9% of trips are under 1386 minutes (~23 hours!) → A few extreme outliers exist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bOMDeGwWBhF"
      },
      "outputs": [],
      "source": [
        "data = data[data.trip_duration_minutes < 55]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4mRN2AMWDg8"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSaNZcZeYMmp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x=data['trip_duration_minutes'])\n",
        "plt.title(\"Trip Duration After Outlier Removal\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2IjeyhDd8Bf"
      },
      "source": [
        "# 3. Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgLWy1gfelOk"
      },
      "outputs": [],
      "source": [
        "data['pickup_hour'] = data.pickup_datetime.dt.hour\n",
        "data['pickup_day'] = data.pickup_datetime.dt.day_of_week\n",
        "data['pickup_day_of_year'] = data.pickup_datetime.dt.day_of_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vm30CMKVgRvr"
      },
      "outputs": [],
      "source": [
        "# Create Distance Feature\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "def haversine_distance(row):\n",
        "    pickup = (row['pickup_latitude'], row['pickup_longitude'])\n",
        "    dropoff = (row['dropoff_latitude'], row['dropoff_longitude'])\n",
        "    return geodesic(pickup, dropoff).km  # Distance in km\n",
        "\n",
        "data['trip_distance_km'] = data.apply(haversine_distance, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kfNjDsRgZmh"
      },
      "outputs": [],
      "source": [
        "data['avg_speed_kmh'] = data.trip_distance_km / (data.trip_duration_minutes / 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aehKRTLTmqw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(x=data['avg_speed_kmh'])\n",
        "plt.title(\"Average speed (kmh)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb6YqcV9T_S-"
      },
      "outputs": [],
      "source": [
        "threshold = data['avg_speed_kmh'].quantile(0.95)\n",
        "threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lu4PM9qU9YN"
      },
      "outputs": [],
      "source": [
        "data = data[data['avg_speed_kmh'] < threshold]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SY3ZO4ligpvR"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPr6D6hwiqNw"
      },
      "source": [
        "# 4. Data Visualization & Insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGy79ZwxisQn"
      },
      "outputs": [],
      "source": [
        "# Trip duration distribution\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data['trip_duration_minutes'], bins=50, kde=True, color='royalblue')\n",
        "\n",
        "plt.xlabel(\"Trip Duration (minutes)\", fontsize=12)\n",
        "plt.ylabel(\"Frequency\", fontsize=12)\n",
        "plt.title(\"Distribution of Trip Duration\", fontsize=14)\n",
        "plt.xlim(0, data['trip_duration_minutes'].quantile(0.99))  # Focus on 99% of data (remove extreme outliers)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iT9onHlkWWG"
      },
      "outputs": [],
      "source": [
        "# Trip duration vs pickup hour\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='pickup_hour', y='trip_duration_minutes', data=data, marker=\"o\", color=\"b\")\n",
        "plt.xlabel(\"Pickup Hour\", fontsize=12)\n",
        "plt.ylabel(\"Trip Duration (minutes)\", fontsize=12)\n",
        "plt.title(\"Trip Duration vs. Pickup Hour\", fontsize=14)\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkzzAy1fm2WD"
      },
      "outputs": [],
      "source": [
        "numeric_data = data.select_dtypes(include=['number'])\n",
        "corr_matrix = numeric_data.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
        "\n",
        "plt.title(\"Correlation Heatmap of Numerical Features\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykgaT7m_oqFB"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NK6kzW_ossh"
      },
      "source": [
        "# 5. Pre-Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSGcuHjRo5mv"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = data.drop(['trip_duration','trip_duration_minutes', 'id', 'pickup_datetime', 'dropoff_datetime'], axis=1)\n",
        "y = data['trip_duration_minutes']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    random_state=42,\n",
        "    test_size=0.2\n",
        ")\n",
        "\n",
        "# Convert categorical columns to string (optional, to prevent dtype issues)\n",
        "X_train['vendor_id'] = X_train['vendor_id'].astype(str)\n",
        "X_test['vendor_id'] = X_test['vendor_id'].astype(str)\n",
        "\n",
        "# Encode 'vendor_id' and 'store_and_fwd_flag' separately\n",
        "le_vendor = LabelEncoder()\n",
        "X_train['vendor_id'] = le_vendor.fit_transform(X_train['vendor_id'])\n",
        "X_test['vendor_id'] = le_vendor.transform(X_test['vendor_id'])\n",
        "\n",
        "le_store = LabelEncoder()\n",
        "X_train['store_and_fwd_flag'] = le_store.fit_transform(X_train['store_and_fwd_flag'])\n",
        "X_test['store_and_fwd_flag'] = le_store.transform(X_test['store_and_fwd_flag'])\n",
        "\n",
        "# Scale features (Don't scale y)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rYqw6beQrgr"
      },
      "outputs": [],
      "source": [
        "print(X_train.isin([np.inf, -np.inf]).sum())  # Count infinities\n",
        "print(X_train.isna().sum())  # Count NaNs\n",
        "\n",
        "print(X_test.isin([np.inf, -np.inf]).sum())  # Count infinities\n",
        "print(X_test.isna().sum())  # Count NaNs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUXKrlg5VsFt"
      },
      "outputs": [],
      "source": [
        "print(\"Mean:\", np.mean(X_train_scaled))\n",
        "print(\"Std Dev:\", np.std(X_train_scaled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLMz7-y_WESB"
      },
      "source": [
        "# 5. Model Training & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aca159f"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "    'Random Forest': RandomForestRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "# Perform cross-validation for each model\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
        "    print(f\"{name} Cross-Validation R² Scores: {scores}\")\n",
        "    print(f\"Mean R² Score: {scores.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a4d93bb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Hyperparameter tuning for RandomForestRegressor\n",
        "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 20]}\n",
        "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_search_rf.fit(X_train_scaled, y_train)\n",
        "print(\"Best Random Forest Parameters:\", grid_search_rf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot n_estimators vs R² score\n",
        "# Convert GridSearchCV results to a DataFrame\n",
        "cv_results = pd.DataFrame(grid_search_rf.cv_results_)\n",
        "\n",
        "# Convert hyperparameters to integer type for plotting\n",
        "cv_results[\"param_n_estimators\"] = cv_results[\"param_n_estimators\"].astype(int)\n",
        "cv_results[\"param_max_depth\"] = cv_results[\"param_max_depth\"].astype(int)\n",
        "\n",
        "# Plot n_estimators vs Mean Test R² Score\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.lineplot(x=cv_results[\"param_n_estimators\"], y=cv_results[\"mean_test_score\"], marker=\"o\")\n",
        "plt.title(\"Effect of n_estimators on Performance\")\n",
        "plt.xlabel(\"Number of Estimators\")\n",
        "plt.ylabel(\"Mean Test R² Score\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iPpVLLBrvooU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "best_model = grid_search_rf.best_estimator_\n",
        "\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "print(\"Test Set R² Score:\", r2_score(y_test, y_pred))\n",
        "print(\"Test Set MSE:\", mean_squared_error(y_test, y_pred))"
      ],
      "metadata": {
        "id": "NeV-HTRVsQAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': best_model.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "id": "Cd5t4VBmqpt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only the top 2 features\n",
        "top_features = ['trip_distance_km', 'avg_speed_kmh']\n",
        "\n",
        "# Convert scaled arrays back to DataFrames\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "\n",
        "# Create new datasets with only these features\n",
        "X_train_selected = X_train_scaled_df[top_features]\n",
        "X_test_selected = X_test_scaled_df[top_features]"
      ],
      "metadata": {
        "id": "c6nXtfawt0XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(X_train_selected, y_train)\n",
        "\n",
        "# Evaluate performance\n",
        "y_pred = best_model.predict(X_test_selected)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.4f}, R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "i5HNdSqtt0Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this project, I explored the NYC Taxi Trip Duration dataset to build a predictive model for trip duration. Below are the key steps taken:\n",
        "\n",
        "1. **Data Preprocessing:**  \n",
        "   - Loaded and examined the dataset.  \n",
        "   - Handled missing values and outliers.  \n",
        "   - Created new features such as `trip_distance_km` and `avg_speed_kmh`.  \n",
        "   - Scaled numerical features for better model performance.  \n",
        "\n",
        "2. **Feature Selection:**  \n",
        "   - Performed feature importance analysis using Random Forest.  \n",
        "   - Identified `trip_distance_km` and `avg_speed_kmh` as the most significant features.  \n",
        "   - Reduced the dataset to only the most relevant features.  \n",
        "\n",
        "3. **Model Training & Evaluation:**  \n",
        "   - Compared multiple models (Linear Regression, Decision Tree, and Random Forest).  \n",
        "   - Used **cross-validation** to evaluate model performance.  \n",
        "   - Fine-tuned the Random Forest model using **GridSearchCV** to optimize hyperparameters.  \n",
        "\n",
        "4. **Results & Insights:**  \n",
        "   - Random Forest outperformed other models with better R² scores.  \n",
        "   - Visualized hyperparameter tuning results to understand model behavior.  \n",
        "   - The final model effectively predicts trip duration based on key trip features.  \n",
        "\n",
        "This project demonstrated the end-to-end machine learning workflow, from **data exploration** to **model optimization**, providing valuable insights into taxi trip durations. 🚖📊  \n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "QQpD9iOewqFL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}